# llm_hallucinations
Work in detecting and mitigating hallucinations for Large Language Models
